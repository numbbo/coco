6th GECCO workshop on Real-Parameter Black-Box Optimization Benchmarking (BBOB 2016)
====================================================================================

Welcome to the web page of the 6th GECCO workshop on Real-Parameter Black-Box Optimization Benchmarking (BBOB 2016),
taking place during GECCO 2016.


    **WORKSHOP ON REAL-PARAMETER BLACK-BOX OPTIMIZATION BENCHMARKING**
        with a focus on bi-objective problems

    | to be held as part of the
    |
    | **2016 Genetic and Evolutionary Computation Conference (GECCO-2016)**
    | July 20-24, Denver, CO, USA
    |
    | Organized by ACM SIGEVO
    | http://gecco-2016.sigevo.org/


| Submission Deadline: Saturday, April 2, 2016
| Webpage: http://coco.gforge.inria.fr/doku.php?id=bbob-2016
| News via http://coco.gforge.inria.fr/register
|


Quantifying and comparing the performance of optimization algorithms
is a difficult and tedious task to achieve. Previously, the Coco
platform has provided tools to ease this process for single-objective
problems by: (1) an implemented, well-motivated benchmark function
testbed, (2) a simple and sound experimental set-up, (3) the generation
of output data and (4) the post-processing and presentation of the
results in graphs and tables. For the first time, this year, we provide
an extension of the Coco platform towards a *bi-objective testbed* with
nearly the same procedure as in previous BBOB workshops.

The remaining tasks for participants are therefore: run your favorite
multiobjective black-box optimizer (old or new) by using the wrappers
provided and run the post-processing procedure (provided as well) that
will generate automatically all the material for a workshop paper
(LaTeX templates are provided). A description of the algorithm and the
discussion of the results completes the paper writing.

We encourage particularly submissions related to biobjective algorithms
for expensive optimization (with a limited budget) and also algorithms
from outside the evolutionary computation community. Please note that
submissions related to the existing single-objective BBOB testbeds
(noiseless and noisy) are still welcome although the focus will be on
the new bi-objective testbed.

During the workshop, algorithms and results will be presented by
the participants. An overall analysis and comparison will be
accomplished by the organizers and the overall process will be
critically reviewed. A plenary discussion on future improvements will,
among others, address the question, of how the testbed should evolve.

Supporting material
-------------------
Code for the benchmark functions and for running the experiments is
provided in Matlab, C, and Python. A Java version will follow soon:
https://github.com/numbbo/numbbo

Get updated by registering here:
http://coco.gforge.inria.fr/register

Documentations of the functions used in the bbob-biobj suite for BBOB 2016 can be found here:
http://numbbo.github.io/bbob-biobj-functions-doc


Important Dates
---------------

* 01/29/2016 release v0.7 of the Coco software with the main functionality
* 02/12/2016 first complete release v0.9 of the software
* 03/18/2016 final release v1.0 for producing the papers
* 04/02/2016 paper and data submission deadline
* 04/19/2016 decision notification
* 20/07/2016 or 21/07/2016 workshop

Organizers:
Anne Auger, Dimo Brockhoff, Nikolaus Hansen, Dejan Tusar, Tea Tusar, and
Tobias Wagner
